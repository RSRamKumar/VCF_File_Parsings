""" INPUT
# This file was generated by vcf-compare.
# The command line was: vcf-compare(v0.1.14-12-gcdb80b8) 100810BL.AF10.indel.recode.vcf.gz 100810OC.AF10.indel.recode.vcf.gz 100810OG.AF10.indel.recode.vcf.gz
#
#VN 'Venn-Diagram Numbers'. Use `grep ^VN | cut -f 2-` to extract this part.
#VN The columns are: 
#VN        1  .. number of sites unique to this particular combination of files
#VN        2- .. combination of files and space-separated number, a fraction of sites in the file
VN	6131	100810OC.AF10.indel.recode.vcf.gz (6.7%)	100810OG.AF10.indel.recode.vcf.gz (6.8%)
VN	6201	100810BL.AF10.indel.recode.vcf.gz (6.8%)	100810OG.AF10.indel.recode.vcf.gz (6.9%)
VN	7605	100810BL.AF10.indel.recode.vcf.gz (8.4%)	100810OC.AF10.indel.recode.vcf.gz (8.3%)
VN	12958	100810BL.AF10.indel.recode.vcf.gz (14.3%)
VN	13678	100810OG.AF10.indel.recode.vcf.gz (15.2%)
VN	13753	100810OC.AF10.indel.recode.vcf.gz (15.1%)
VN	63769	100810BL.AF10.indel.recode.vcf.gz (70.4%)	100810OC.AF10.indel.recode.vcf.gz (69.9%)	100810OG.AF10.indel.recode.vcf.gz (71.0%)
#SN Summary Numbers. Use `grep ^SN | cut -f 2-` to extract this part.
SN	Number of REF matches:	61290
SN	Number of ALT matches:	55061
SN	Number of REF mismatches:	2479
SN	Number of ALT mismatches:	6229
SN	Number of samples in GT comparison:	0
# Number of sites lost due to grouping (e.g. duplicate sites): lost, %lost, read, reported, file
SN	Number of lost sites:	9157	9.2%	99690	90533	100810BL.AF10.indel.recode.vcf.gz
SN	Number of lost sites:	9387	9.3%	100645	91258	100810OC.AF10.indel.recode.vcf.gz
SN	Number of lost sites:	9679	9.7%	99458	89779	100810OG.AF10.indel.recode.vcf.gz

"""

"""
#OUTPUT
Sample ID	BL	OC	OG
100810	168376	168376	168376
100810	2699	0	2699
100810	0	3259	3259
100810	4133	4133	0
100810	0	0	6070
100810	6273	0	0
100810	0	6693	0
Total	181481		

"""

import os
import pandas as pd
import numpy as np
 
import sys 
filename = sys.argv[1]
 
sample_id = filename.split('.')[0]

outputfilename, extension = os.path.splitext(filename)

 

parsed_data = {}
fin=  open(filename, 'r')
for line in fin:
    if line.startswith('VN'):
        VN, number, *value = line.strip().split('\t')
        parsed_data[number] = value
         
fin.close()

df = pd.DataFrame(columns=['BL', 'OC', 'OG'], index=list(range(len(parsed_data))))
 
 
for index, key in enumerate(parsed_data.keys()) :
    #print(key, parsed_data[key])
    value = parsed_data[key]
    for val in value:
        id = val.split('.')[0][-2:]
        df.loc[index,id] = int(key)
     

df.insert(0,'Sample ID',[sample_id]*len(parsed_data))
 
df.fillna(value= 0, inplace=True)
df = df.apply(np.roll, shift=1)
df.loc['Total'] = ['Total',df['BL'].sum(), '', '']  # adding a row
 
#print(df)
 
 
df.to_csv( '{}_out.csv'.format(outputfilename), sep='\t', index=False)
df.to_excel( '{}_out.xlsx'.format(outputfilename), index=False)
